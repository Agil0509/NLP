{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPOQffHHQKWr8O5CKaCXrH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Agil0509/NLP/blob/main/gpt_dev_main(S%C9%99m%C9%99d_Vur%C4%9Fun).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA0v91BDatZK"
      },
      "outputs": [],
      "source": [
        "unwanted_chars = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9','\\n']\n",
        "\n",
        "with open('/content/Semed_Vurgun_seirleri.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "for char in unwanted_chars:\n",
        "    text = text.replace(char, '  ')\n",
        "\n",
        "with open('Semed_Vurgun_cleaned_file.txt', 'w', encoding='utf-8') as file:\n",
        "    file.write(text)\n",
        "\n",
        "# print(\"Data cleaned and saved to 'cleaned_file.txt'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "CpCklO4QbFPA",
        "outputId": "ee404cbb-068a-4b37-8f94-8c295f7a4068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  CAVANLARA XİTAB  Mənim düşkün könlüm sizdən eləyir  Bu fərz*   olan təmənnanı, cavanlar.  Unutmayın bəşər sizdən diləyır,  Elm, ədəb, həm irfani, cavanlar.  Bəşər gülşəninin bülbülüsünüz,  Şanlı firqəmizin sağ əlisiniz,  Zalım əllilərin cəlladısınız,  Dəvasızların dərmanı, cavanlar.  Carəsız dərdlərə çarə etməyə,  Quşu vurub həm imdada yetməyə,  Həyatı ağ, nə kı qarə etməyə  Sərf ediniz hər zamanı, cavanlar.  Yaşayarsa bəşər, yaşar sizinlə,  Soğulmuş  †   çeşmələr axar sizinlə,  Zalımlar geridən baxar, sizinlə  İnqilabın qəhrəmanı, cavanlar.  Çünki tələb edir zavallı bəşər,  Gərək keçə sizdən ona bir əsər.  Yoxsa qan ağlayar yenə sərbəsər,  Olmaz da dərdinə çarə, cavanlar.  İstəsəniz, ölkəmiz, abad olar,  Ellərin məhbusları azad olar,  Onda da Vurğunun könlü şad olar,  Verər sizə can qurbanı, cavanlar.                *Vacib, zəruri  †Qurumuş, tutulmuş             MAYDAN  ...Haman sənə məhəl-məmuriyyətim*   olan Köçəsgər kəndindən         rübləyə bir maydan at almşam. Bu qiymətə həqiq'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH2QlnTwbHDu",
        "outputId": "4ad23d51-e504-4cf9-b54a-318821645e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "872234"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(''.join(set(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOInQaOrbRtJ",
        "outputId": "e6c73481-648c-41e3-9fea-b38fffb38f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(text)"
      ],
      "metadata": {
        "id": "H_D-TH5ibXfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b728ac6-55db-4029-b283-c5c284d73876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\x01',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '>',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '§',\n",
              " '°',\n",
              " '»',\n",
              " 'Ç',\n",
              " 'Ö',\n",
              " 'Ü',\n",
              " 'ä',\n",
              " 'ç',\n",
              " 'ö',\n",
              " 'ü',\n",
              " 'Ğ',\n",
              " 'ğ',\n",
              " 'İ',\n",
              " 'ı',\n",
              " 'Ş',\n",
              " 'ş',\n",
              " 'Ə',\n",
              " 'ə',\n",
              " '–',\n",
              " '—',\n",
              " '‘',\n",
              " '’',\n",
              " '“',\n",
              " '”',\n",
              " '†',\n",
              " '‡',\n",
              " '…',\n",
              " '★'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "batch_size = 64\n",
        "block_size = 256\n",
        "max_iters = 1500\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.2\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "\n",
        "stoi = {}\n",
        "for i,ch in enumerate(chars):\n",
        "  stoi[ch] = i\n",
        "\n",
        "itos = {}\n",
        "for i,ch in enumerate(chars):\n",
        "  itos[i] = ch\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(text),dtype = torch.long)\n",
        "\n",
        "n= int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data)- block_size,(batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x,y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train','val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X,Y = get_batch(split)\n",
        "      logits, loss = model(X,Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embd,head_size,bias = False)\n",
        "    self.query = nn.Linear(n_embd,head_size,bias = False)\n",
        "    self.value = nn.Linear(n_embd,head_size,bias = False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
        "\n",
        "  def forward(self,x):\n",
        "    B, T,C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "\n",
        "    wei = q @ k.transpose(-2,-1) * C**-0.5\n",
        "    wei = wei.masked_fill(self.tril[:T,: T] == 0, float('-inf'))\n",
        "    wei = F.softmax(wei, dim = -1)\n",
        "    v = self.value(x)\n",
        "    out = wei  @ v\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_heads, head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "    self.proj = nn.Linear(n_embd,n_embd)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = torch.cat([h(x) for h in self.heads],dim =-1)\n",
        "    out = self.proj(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,n_embd):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(n_embd,4* n_embd),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(4* n_embd, n_embd),\n",
        "      nn.Dropout(dropout)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, n_embd,n_head):\n",
        "    super().__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa = MultiHeadAttention(n_head,head_size)\n",
        "    self.ffwd = FeedForward(n_embd)\n",
        "    self.ln1 = nn.LayerNorm(n_embd)\n",
        "    self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x+ self.sa(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x\n",
        "\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "\n",
        "    self.blocks = nn.Sequential(*[Block(n_embd, n_head = n_head) for _ in range(n_layer)])\n",
        "    self.ln_f = nn.LayerNorm(n_embd)\n",
        "    # self.sa_head = Head(n_embd)\n",
        "    # self.sa_heads = MultiHeadAttention(4,n_embd//4)\n",
        "    # self.ffwd = FeedForward(n_embd)\n",
        "\n",
        "    # self.blocks = nn.Sequential(\n",
        "    #   Block(n_embd, n_head = 4),\n",
        "    #   Block(n_embd, n_head = 4),\n",
        "    #   Block(n_embd, n_head = 4),\n",
        "    #   nn.LayerNorm(n_embd)\n",
        "    # )\n",
        "\n",
        "    self.lm_head = nn.Linear(n_embd,vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "\n",
        "    B, T= idx.shape\n",
        "    token_emb = self.token_embedding_table(idx)\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "    x = token_emb+pos_emb\n",
        "\n",
        "    # x = self.sa_head(x)\n",
        "    # x = self.sa_heads(x)\n",
        "    # x = self.ffwd(x)\n",
        "    x = self.blocks(x)\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)    #B - batch_size , T - time_step , C - Chanel\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "      for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:,-block_size:]\n",
        "        logits,loss = self(idx_cond)\n",
        "\n",
        "        # logits, loss = self(idx)\n",
        "        logits = logits[:, -1, :]\n",
        "        probs = F.softmax(logits, dim = -1)\n",
        "        idx_next = torch.multinomial(probs, num_samples = 1)\n",
        "        idx = torch.cat((idx, idx_next), dim = 1)   #cat = concat\n",
        "      return idx\n",
        "\n",
        "model = GPTLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "\n",
        "print(sum(p.numel() for p in m.parameters()) / 1e6, 'M parameters')\n",
        "\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr= 1e-3)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "  if iter % eval_iters == 0:\n",
        "    losses = estimate_loss()\n",
        "    print(f'step {iter}: loss {losses}')\n",
        "\n",
        "  xb, yb = get_batch('train')\n",
        "  logits, loss = model(xb,yb)\n",
        "  optimizer.zero_grad(set_to_none = True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "context = idx = torch.zeros((1, 1), dtype = torch.long, device = device)\n",
        "\n",
        "print(decode(m.generate(context, max_new_tokens = 1000)[0].tolist()))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfSf7b_ReFWW",
        "outputId": "087e1d62-8127-4f67-96ec-f4590dd5ddda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda\n",
            "10.815844 M parameters\n",
            "step 0: loss {'train': tensor(5.0154), 'val': tensor(5.0197)}\n",
            "step 200: loss {'train': tensor(2.4865), 'val': tensor(2.4760)}\n",
            "step 400: loss {'train': tensor(1.9778), 'val': tensor(1.9645)}\n",
            "step 600: loss {'train': tensor(1.7539), 'val': tensor(1.7532)}\n",
            "step 800: loss {'train': tensor(1.5998), 'val': tensor(1.6430)}\n",
            "step 1000: loss {'train': tensor(1.4830), 'val': tensor(1.5811)}\n",
            "step 1200: loss {'train': tensor(1.3882), 'val': tensor(1.5446)}\n",
            "step 1400: loss {'train': tensor(1.2924), 'val': tensor(1.5430)}\n",
            "\u0001niyanın uynuzəhərdən.  Sadə o gözəl və dövrəmizarı  Oturmuşdur başında mənalı bir dən,  Utanmadın öz görəmizə!  Yaman, içdi dünya köçəcəəyəm mən...  Biz eyvanı da qəlbimdə sülmisən?  İnsan gəimizdir niyət - arabən,  Doqqussa, dünya bizim Bəxtiyar,  Bizim Sakit o, qaşlar dilbəti  Xasın, bizim gözlərin də bircəsi  Öpərin ilk ömür yadigar...  Ucadır buğ sardaca ki,  Atılır zimzənət axır düzü  Zəhərlənəci nəğməsin ürək...  Tüstüləcək gözlə gülümsüz yaşılacaq...  Şığın-gözü var;  Bir gəl, göy də bir güldürlüyə  Sən dəyişəcək sözməsini -  O nə indi gülür, nə də...  Bütün məhəbbətlə, bu göz yalqarı,  Açılır yüz bəzən atışmayır?  Qara qəlbin, məncəm sənə danış,  Sadət ilham alır yemkək arzusun!  Başqa bir fınalt! Ürək sənəti!  Hər vətən də radiəti, qəlbi,  Yenə də nə oyaman nə də təhqi*  *** *, təmə nə ac var,  Nə də bəlkə mənim böyükdür!  Gəlim, hazıram görək, həsrətim var.  Ürəyin fəhəngələrdən ilhamımı,  Deyir insan, hər kəndən ömür şübhəsi  Səyyar gedər, yaradan odur.  Elə bil etmiş hürmüz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = idx = torch.zeros((1, 1), dtype = torch.long, device = device)\n",
        "\n",
        "print(decode(m.generate(context, max_new_tokens = 1000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTUh-eZ7AWMs",
        "outputId": "9853f351-07cb-4015-ca75-4a801c196dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u0001əşmə kimi, öz rəzzi baş kimi  Çəkib sözlə suram meyləşənlər.  O can var çoxmuşamış sinəsillər;  Osağ səhərin zamanlar, suları –  Qaya gəlir, yenə də atır salır;  Dəyişmiş bulaqların kimi salır –  Üzəndən içəndə həqi o taləmi  Sən, əlbətdir zəfərələr...  Əli, Ölmüş bir qəsəndə  Yenə ürək sarı oturan sayıqda;  Nə od içim? Tökərin var, nə torpağa  Mətən, yenə köynət ilhama aparmaq?  Dedim ki, son gözəl meyas?  ardım:  Gözəllər görünən guzludur...  Neçin bunlar  Səninlə qanad alır,  Keçim də böyük ürəyi.  Aşıq qalib kelib,  hələ kən qayıtmadım büz gülən.  Dedim kimi kamalınma ürək qüyərdə,  Ölünc ilimdəki qaldımızmı?  Çəndəmi dərdli, bir yandırsan,  Unun girməsinidən qaldırar  Kənabın qayğusu gələcəkdir!  Beşidir əzəldən, sən də!  Elə bil gündə bəlkə bir günəşdə.  Tən təzən şörək yeyib alib kəsə  Qoy Sən bizim BAYRamanım Nələrin?   **  , ona, bəlkə həməni bəxtəriyəm  Deyən Cavab düzdü yatan,  Seyə bir vaxtımın öz qəlbində  Həyata salıb yamr eləm, heçlərim!  İndidə mərin, qüvvət yellərim va\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzFGSEjfEchd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}